{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91053000",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb33c5",
   "metadata": {},
   "source": [
    "After the the creation of the database, we connect to the database and perform the following:\n",
    "- Determine number of rows with blank cells. Because there were only five, we dropped those cells\n",
    "- We dropped the happinessrank, lat, and lng columns because they were unnecessary \n",
    "- We created a seprate dataframe and dropped the index, then exported for use in R Studio (both simple linear calculations and a multiple linear regression were perfored in R Studio -- see images for results). Addionally, in R Studio the data was split into training and testing sets by creating two random sets (P1 - training,  and P2 - testing). P1 contains the first 50 rows of random data, P2 contains the rest.\n",
    "- Finally, we dropped the country column because it was no longer necessary and changed the data type from object to float.\n",
    "\n",
    "This model was chosen because we are able to measure each (and several in the case of multiple linear regression), features against \"happinessscore\" to see how/whether they are related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa708d",
   "metadata": {},
   "source": [
    "## Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7b0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import psycopg2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1903fb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'postgres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-abd138cb4905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Connection parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtn_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtn_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m param_dic = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"host\"\u001b[0m      \u001b[0;34m:\u001b[0m \u001b[0;34m\"whr.csnc4l4qvlqd.us-east-2.rds.amazonaws.com\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Bootcamp/My_Class_Repos/happy_places/MachineLearning/Supervised_ML/tn_config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0musername\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostgres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUCBwhr2021\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'postgres' is not defined"
     ]
    }
   ],
   "source": [
    "# Connection parameters\n",
    "from tn_config import username\n",
    "from tn_config import password\n",
    "param_dic = {\n",
    "    \"host\"      : \"whr.csnc4l4qvlqd.us-east-2.rds.amazonaws.com\",\n",
    "    \"database\"  : \"postgres\",\n",
    "    \"user\"      : \"username\",\n",
    "    \"password\"  : \"password\"\n",
    "}\n",
    "\n",
    "# Create connect function to connect to PostgresSQL server\n",
    "def connect(param_dic):\n",
    "    conn = None\n",
    "    try:\n",
    "        print(\"Connecting to the PostgreSQL database...\")\n",
    "        conn = psycopg2.connect(**param_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1)\n",
    "    print (\"Connection successful.\")\n",
    "    return conn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a961b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the dataframe\n",
    "def postgresql_to_dataframe(conn, select_query, column_names):\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(select_query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            cursor.close()\n",
    "    \n",
    "    # Get list of tuples\n",
    "    tuples = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    \n",
    "    # Create pandas dataframe\n",
    "    df = pd.DataFrame(tuples, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5472253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = connect(param_dic)\n",
    "\n",
    "column_names = [\"country\", \"happinessrank\", \"happinessscore\", \"gdp\", \"family\", \"lifeexpectancy\", \"freedom\", \"generosity\", \"trust\", \"lat\", \"lng\", \"alcohol_liperyear\"]\n",
    "df = postgresql_to_dataframe(conn, \"select * from whr_2019\", column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47beef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display countries with null values\n",
    "df1 = df[df.isna().any(axis=1)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are only 5 countries, drop countries with null values\n",
    "df = df.dropna()\n",
    "df2 = df[df.isna().any(axis=1)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4409c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop unnecessariy columns\n",
    "df = df.drop(columns=[\"happinessrank\", \"lat\", \"lng\"], axis=1)\n",
    "df = df.fillna(value=np.nan)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write df to csv file for R Studio \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_csv(\"sml_linreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd80c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop \"country\" column and make type float\n",
    "df = df.drop(columns=[\"country\"])\n",
    "df = df[0:153].astype(float, errors = 'raise')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaaf706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431de98",
   "metadata": {},
   "source": [
    "## Predicting GDP - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP\n",
    "X = df.gdp\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d8f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.gdp)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"GDP\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b4ebb",
   "metadata": {},
   "source": [
    "## Predicting Family - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a92c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "X = df.family\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1625757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7d61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.family)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Family\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12562d19",
   "metadata": {},
   "source": [
    "## Predicting Life Expectancy - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Life Expectancy\n",
    "X = df.lifeexpectancy\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3facc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e8f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.lifeexpectancy)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Life Expectancy\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca5d59",
   "metadata": {},
   "source": [
    "## Predicting Freedom - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freedom\n",
    "X = df.freedom\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe9007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.freedom)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Freedom\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b6070",
   "metadata": {},
   "source": [
    "## Predicting Trust - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0940759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trust\n",
    "X = df.trust\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c347fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.trust)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Trust\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe12d56",
   "metadata": {},
   "source": [
    "## Predicting Generosity - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generosity\n",
    "X = df.generosity\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.generosity)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Generosity\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3f080",
   "metadata": {},
   "source": [
    "## Predicting Alcohol Consumption - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71965933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcohol Consumption\n",
    "X = df.alcohol_liperyear\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((149, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29579f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.alcohol_liperyear)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Alcohol Consumption\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
