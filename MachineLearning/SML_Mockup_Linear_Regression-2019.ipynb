{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7b0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import psycopg2\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1903fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection parameters\n",
    "param_dic = {\n",
    "    \"host\"      : \"whr.csnc4l4qvlqd.us-east-2.rds.amazonaws.com\",\n",
    "    \"database\"  : \"postgres\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"UCBwhr2021\"\n",
    "}\n",
    "\n",
    "# Create connect function to connect to PostgresSQL server\n",
    "def connect(param_dic):\n",
    "    conn = None\n",
    "    try:\n",
    "        print(\"Connecting to the PostgreSQL database...\")\n",
    "        conn = psycopg2.connect(**param_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1)\n",
    "    print (\"Connection successful.\")\n",
    "    return conn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a961b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the dataframe\n",
    "def postgresql_to_dataframe(conn, select_query, column_names):\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(select_query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            cursor.close()\n",
    "    \n",
    "    # Get list of tuples\n",
    "    tuples = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    \n",
    "    # Create pandas dataframe\n",
    "    df = pd.DataFrame(tuples, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5472253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = connect(param_dic)\n",
    "\n",
    "column_names = [\"country\", \"happinessrank\", \"happinessscore\", \"gdp\", \"family\", \"lifeexpectancy\", \"freedom\", \"generosity\", \"trust\", \"lat\", \"lng\", \"alcohol_liperyear\"]\n",
    "df = postgresql_to_dataframe(conn, \"select * from whr_2019\", column_names)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4409c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop unnecessariy columns\n",
    "df = df.drop(columns=[\"country\", \"happinessrank\", \"lat\", \"lng\"], axis=1)\n",
    "df = df.fillna(value=np.nan)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:7] = df[0:7].astype(float, errors = 'raise')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431de98",
   "metadata": {},
   "source": [
    "## Predicting GDP - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP\n",
    "X = df.gdp\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((154, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d8f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.gdp)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"GDP\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b4ebb",
   "metadata": {},
   "source": [
    "## Predicting Family - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a92c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "X = df.family\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((777, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1625757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7d61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.family)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Family\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12562d19",
   "metadata": {},
   "source": [
    "## Predicting Life Expectancy - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Life Expectancy\n",
    "X = df.lifeexpectancy\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((777, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3facc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e8f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.lifeexpectancy)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Life Expectancy\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca5d59",
   "metadata": {},
   "source": [
    "## Predicting Freedom - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freedom\n",
    "X = df.freedom\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((777, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe9007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.freedom)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Freedom\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b6070",
   "metadata": {},
   "source": [
    "## Predicting Trust - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0940759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trust\n",
    "X = df.trust\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((777, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c347fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.trust)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Trust\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe12d56",
   "metadata": {},
   "source": [
    "## Predicting Generosity - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generosity\n",
    "X = df.generosity\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((777, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.generosity)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Generosity\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3f080",
   "metadata": {},
   "source": [
    "## Predicting Alcohol Consumption - Happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71965933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcohol Consumption\n",
    "X = df.alcohol_liperyear\n",
    "y = df.happinessscore\n",
    "X_b = np.c_[np.ones((777, 1)), X]  # Adding the bias term which is equal to 1\n",
    "\n",
    "# Dividing the data into train and test sets    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta_optimize = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data with the obtained feature weights\n",
    "y_pred = X_test.dot(theta_optimize)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29579f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array(df.alcohol_liperyear)\n",
    "y = np.array(df.happinessscore)\n",
    "plt.xlabel(\"Alcohol Consumption\")\n",
    "plt.ylabel(\"Happiness\")\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
